{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam Image Analysis \n",
    "David Basilio Rodriguez Cortez\n",
    "s231486"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color, io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "from skimage.morphology import erosion, dilation, binary_erosion, binary_dilation\n",
    "from skimage.morphology import disk\n",
    "from skimage.morphology import square\n",
    "from skimage.filters import prewitt\n",
    "from skimage.filters import median\n",
    "from skimage import segmentation\n",
    "from skimage import measure\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage.transform import rescale, resize\n",
    "from skimage import data, morphology, measure, segmentation, img_as_ubyte\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import gaussian\n",
    "from skimage.color import label2rgb\n",
    "from scipy.spatial import distance\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import EuclideanTransform\n",
    "from skimage.transform import SimilarityTransform\n",
    "from skimage.transform import warp\n",
    "from skimage.transform import swirl\n",
    "from skimage.transform import matrix_transform\n",
    "import glob\n",
    "from sklearn.decomposition import PCA\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUXILIAR FUNCTION ###\n",
    "def create_u_byte_image_from_vector(im_vec, height, width, channels):\n",
    "    min_val = im_vec.min()\n",
    "    max_val = im_vec.max()\n",
    "\n",
    "    # Transform to [0, 1]\n",
    "    im_vec = np.subtract(im_vec, min_val)\n",
    "    im_vec = np.divide(im_vec, max_val - min_val)\n",
    "    im_vec = im_vec.reshape(height, width, channels)\n",
    "    im_out = img_as_ubyte(im_vec)\n",
    "    return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA FROM TXT FILE ###\n",
    "def pca_on_single_data(x):\n",
    "    n_feat = x.shape[1]\n",
    "    n_obs = x.shape[0]\n",
    "    print(f\"Number of features: {n_feat} and number of observations: {n_obs}\")\n",
    "\n",
    "    mn = np.mean(x, axis=0)\n",
    "    data = x - mn\n",
    "\n",
    "    mins = data.min(axis=0)\n",
    "    maxs = data.max(axis=0)\n",
    "    spread = maxs - mins\n",
    "    data = data / spread\n",
    "\n",
    "    print(f\"Answer: Amount of Sodium {data[0][1]:.2f}\")         # Fixed value of data normalized\n",
    "    c_x = np.cov(data.T)\n",
    "\n",
    "    print(f\"Answer: Covariance matrix at (0, 0): {c_x[0][0]:.3f}\") # Fixed value of covariance matrix\n",
    "\n",
    "    values, vectors = np.linalg.eig(c_x)\n",
    "\n",
    "    v_norm = values / values.sum() * 100\n",
    "    plt.plot(v_norm)\n",
    "    plt.xlabel('Principal component')\n",
    "    plt.ylabel('Percent explained variance')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.show()\n",
    "\n",
    "    answer = v_norm[0] + v_norm[1] + v_norm[2]              # Fixed number of PC\n",
    "    print(f\"Answer: Variance explained by the first three PC: {answer:.2f}\")\n",
    "\n",
    "    # Project data\n",
    "    pc_proj = vectors.T.dot(data.T)\n",
    "\n",
    "    abs_pc_proj = np.abs(pc_proj)\n",
    "    max_proj_val = np.max(abs_pc_proj)                      # Fixed max value of PC\n",
    "    print(f\"Answer: maximum absolute projected answer {max_proj_val}\")\n",
    "\n",
    "\n",
    "### DETECT CHANGES IN IMAGES (BACKGROUND VS NEW FRAME) ###\n",
    "def change_detection(background_path, new_frame_path):\n",
    "    name_1 = background_path\n",
    "    name_2 = new_frame_path\n",
    "\n",
    "    im_1 = io.imread(name_1)\n",
    "    im_2 = io.imread(name_2)\n",
    "    im_1_g = color.rgb2gray(im_1)\n",
    "    im_2_g = color.rgb2gray(im_2)\n",
    "\n",
    "    average_val_org = np.average(im_1_g[150:200, 150:200]) # Fixed area\n",
    "    print(f\"Average_value {average_val_org:.2f}\")\n",
    "\n",
    "    alpha = 0.90\n",
    "    im_new_background = alpha * im_1_g + (1 - alpha) * im_2_g\n",
    "    average_val = np.average(im_new_background[150:200, 150:200]) # Fixed area\n",
    "    print(f\"Answer: average_value {average_val:.2f}\")\n",
    "\n",
    "    dif_thres = 0.1                                     # Fixed threshold\n",
    "    dif_img = np.abs(im_new_background - im_2_g)\n",
    "    dif_bin = (dif_img > dif_thres)\n",
    "    io.imshow(dif_bin)\n",
    "    io.show()\n",
    "    changed_pixels = np.sum(dif_bin)\n",
    "    print(f\"Answer: Changed pixels {changed_pixels:.0f}\")\n",
    "\n",
    "\n",
    "### CALCULATE SYSTEM FRAME RATE ###\n",
    "def system_frame_rate():\n",
    "    # bytes per second\n",
    "    transfer_speed = 24000000                       # Fixed transfer speed\n",
    "    image_mb = 1600 * 800 * 3                       # Fixed image size\n",
    "    images_per_second = transfer_speed / image_mb\n",
    "    print(f\"Images transfered per second {images_per_second:.3f}\")\n",
    "\n",
    "    proc_time = 0.230                               # Fixed processing time\n",
    "    proc_per_second = 1/proc_time\n",
    "    print(f\"Images processed per second {proc_per_second:.1f}\")\n",
    "\n",
    "    max_fps = min(proc_per_second, images_per_second)\n",
    "    print(f\"System framerate {max_fps:.1f}\")\n",
    "\n",
    "    img_per_sec = 6.25                              # Fixed image per second\n",
    "    transfer_speed = img_per_sec * image_mb\n",
    "    print(f\"Computed transfer speed {transfer_speed}\")\n",
    "\n",
    "\n",
    "### HSV THRESHOLDING ###\n",
    "def nike_rgb_hsv_thresholds(img_path):\n",
    "    im_name = img_path\n",
    "    im_org = io.imread(im_name)\n",
    "    hsv_img = color.rgb2hsv(im_org)\n",
    "    hue_img = hsv_img[:, :, 0]                      # Fixed hue image\n",
    "\n",
    "    io.imshow(hue_img)\n",
    "    plt.title('Hue image')\n",
    "    io.show()\n",
    "\n",
    "    letters = (0.3 < hue_img) & (hue_img < 0.7)     # Fixed threshold\n",
    "    io.imshow(letters)\n",
    "    plt.title('Segmented Letters')\n",
    "    io.show()\n",
    "\n",
    "    footprint = disk(8)\n",
    "    dilated = dilation(letters, footprint)\n",
    "\n",
    "    result = dilated.sum()\n",
    "    print(f\"Answer: Result {result}\")\n",
    "\n",
    "    io.imshow(dilated)\n",
    "    plt.title('Dilated letters')\n",
    "    io.show()\n",
    "\n",
    "\n",
    "### FILTERING WITH MEDIAN FILTER ###\n",
    "def filtering(img_path):\n",
    "    im_name = img_path\n",
    "    im_org = io.imread(im_name)\n",
    "    io.imshow(im_org)\n",
    "    plt.title('Letters')\n",
    "    io.show()\n",
    "\n",
    "    img_g = color.rgb2gray(im_org)\n",
    "\n",
    "    size = 8                                                        # Fixed square size\n",
    "    med_img = median(img_g, square(size))\n",
    "    io.imshow(med_img)\n",
    "    plt.title('Filtered letters')\n",
    "    io.show()\n",
    "    print(f\"Answer: value at (100,100): {med_img[100, 100]:.2f}\")   # Fixed value at (100, 100)\n",
    "\n",
    "    # edge_img = prewitt(img_as_ubyte(im_org))\n",
    "    # min_val = edge_img.min()\n",
    "    # max_val = edge_img.max()\n",
    "    # io.imshow(edge_img, vmin=min_val, vmax=max_val, cmap=\"terrain\")\n",
    "    # plt.title('Prewitt filtered image')\n",
    "    # io.show()\n",
    "    #\n",
    "    # bin_edges = edge_img > 0.06\n",
    "    # io.imshow(bin_edges)\n",
    "    # plt.title('Binary edges. Manual threshold')\n",
    "    # io.show()\n",
    "    #\n",
    "    # num_pixels = bin_edges.sum()\n",
    "    # print(f\"Number of edge pixels {num_pixels}\")\n",
    "\n",
    "\n",
    "### BLOB CLASSIFICATION ###\n",
    "def letters_blob_analysis(img_path):\n",
    "    im_name = img_path\n",
    "    im_org = io.imread(im_name)\n",
    "    io.imshow(im_org)\n",
    "    plt.title('Letters')\n",
    "    io.show()\n",
    "\n",
    "    img_r = im_org[:, :, 0]\n",
    "    img_g = im_org[:, :, 1]\n",
    "    img_b = im_org[:, :, 2]\n",
    "\n",
    "    img_letters = (img_r > 100) & (img_g < 100) & (img_b < 100)     # Fixed threshold\n",
    "\n",
    "    footprint = disk(3)                                             # Fixed disk size\n",
    "    eroded = erosion(img_letters, footprint)                        # Fixed morphology operation\n",
    "\n",
    "    result = eroded.sum()\n",
    "    print(f\"Answer: eroded {result}\")\n",
    "\n",
    "    # img_g = color.rgb2gray(im_org)\n",
    "\n",
    "    # size = 8\n",
    "    # footprint = np.ones([size, size])\n",
    "    # med_img = median(img_g, footprint)\n",
    "    io.imshow(eroded)\n",
    "    plt.title('Filtered letters')\n",
    "    io.show()\n",
    "    # print(f\"Answer: value at (100,100): {med_img[100, 100]:.2f}\")\n",
    "\n",
    "    label_img = measure.label(eroded)\n",
    "    n_labels = label_img.max()\n",
    "    print(f\"Number of labels: {n_labels}\")\n",
    "\n",
    "    region_props = measure.regionprops(label_img)\n",
    "\n",
    "    # areas = np.array([prop.area for prop in region_props])\n",
    "\n",
    "    min_area = 1000                                                # Fixed areas and perimeter                                             \n",
    "    max_area = 4000\n",
    "    min_perm = 300\n",
    "\n",
    "    # Create a copy of the label_img\n",
    "    label_img_filter = label_img.copy()\n",
    "    for region in region_props:\n",
    "        a = region.area\n",
    "        p = region.perimeter\n",
    "\n",
    "        if p < min_perm or a < min_area or a > max_area:\n",
    "            # set the pixels in the invalid areas to background\n",
    "            for cords in region.coords:\n",
    "                label_img_filter[cords[0], cords[1]] = 0\n",
    "\n",
    "    # Create binary image from the filtered label image\n",
    "    i_letter = label_img_filter > 0\n",
    "    # show_comparison(img, i_area, 'Found spleen based on area')\n",
    "    io.imshow(i_letter)\n",
    "    io.show()\n",
    "\n",
    "\n",
    "### DICOM AND ROI ANALYSIS ###\n",
    "def kidney_pixel_analysis(data_path):\n",
    "    in_dir = data_path\n",
    "    im_name = \"1-166.dcm\"                                       # Fixed dicom name             \n",
    "\n",
    "    ct = dicom.read_file(in_dir + im_name)\n",
    "    img = ct.pixel_array\n",
    "\n",
    "    kidney_l_roi = io.imread(in_dir + 'kidneyROI_l.png')        # Fixed ROI name\n",
    "    kidney_l_mask = kidney_l_roi > 0\n",
    "    kidney_l_values = img[kidney_l_mask]\n",
    "    (mu_kidney_l, std_kidney_l) = norm.fit(kidney_l_values)\n",
    "    print(f\"Answer: kidney_l: Average {mu_kidney_l:.0f} standard deviation {std_kidney_l:.0f}\")\n",
    "\n",
    "    kidney_r_roi = io.imread(in_dir + 'kidneyROI_r.png')        # Fixed ROI name\n",
    "    kidney_r_mask = kidney_r_roi > 0\n",
    "    kidney_r_values = img[kidney_r_mask]\n",
    "    (mu_kidney_r, std_kidney_r) = norm.fit(kidney_r_values)\n",
    "    print(f\"Answer: kidney_r: Average {mu_kidney_r:.0f} standard deviation {std_kidney_r:.0f}\")\n",
    "\n",
    "\n",
    "    #\n",
    "    # aorta_roi = io.imread(in_dir + 'AortaROI.png')\n",
    "    # aorta_mask = aorta_roi > 0\n",
    "    # aorta_values = img[aorta_mask]\n",
    "    # (mu_aorta, std_aorta) = norm.fit(aorta_values)\n",
    "    # print(f\"Aorta: Average {mu_aorta:.0f} standard deviation {std_aorta:.0f}\")\n",
    "    #\n",
    "    liver_roi = io.imread(in_dir + 'LiverROI.png')              # Fixed ROI name\n",
    "    liver_mask = liver_roi > 0\n",
    "    liver_values = img[liver_mask]\n",
    "    (mu_liver, std_liver) = norm.fit(liver_values)\n",
    "    # print(f\"Answer: liver: Average {mu_liver:.0f} standard deviation {std_liver:.0f}\")\n",
    "    # min_hu = mu_liver - np.sqrt(3) * std_liver\n",
    "    # max_hu = mu_liver + np.sqrt(3) * std_liver\n",
    "    min_hu = mu_liver - std_liver\n",
    "    max_hu = mu_liver + std_liver\n",
    "    print(f\"Answer: HU limits : {min_hu:0.2f} {max_hu:0.2f}\")\n",
    "\n",
    "    bin_img = (img > min_hu) & (img < max_hu)\n",
    "    liver_label_colour = color.label2rgb(bin_img)\n",
    "    io.imshow(liver_label_colour)\n",
    "    plt.title(\"First Liver estimate\")\n",
    "    io.show()\n",
    "\n",
    "    footprint = disk(3)                                         # Fixed disk size                                \n",
    "    dilated = dilation(bin_img, footprint)\n",
    "\n",
    "    footprint = disk(10)                                        # Fixed disk size            \n",
    "    eroded = erosion(dilated, footprint)\n",
    "    io.imshow(eroded)\n",
    "    plt.title(\"Second Liver estimate\")\n",
    "    io.show()\n",
    "\n",
    "    footprint = disk(10)                                        # Fixed disk size\n",
    "    dilated = dilation(eroded, footprint)\n",
    "    io.imshow(dilated)\n",
    "    plt.title(\"Third Liver estimate\")\n",
    "    io.show()\n",
    "\n",
    "    label_img = measure.label(dilated)\n",
    "    n_labels = label_img.max()\n",
    "    print(f\"Number of labels: {n_labels}\")\n",
    "\n",
    "    region_props = measure.regionprops(label_img)\n",
    "\n",
    "    min_area = 1500                                            # Fixed areas and perimeter      \n",
    "    max_area = 7000\n",
    "    min_perm = 300\n",
    "\n",
    "    # Create a copy of the label_img\n",
    "    label_img_filter = label_img.copy()\n",
    "    for region in region_props:\n",
    "        a = region.area\n",
    "        p = region.perimeter\n",
    "\n",
    "        if p < min_perm or a < min_area or a > max_area:\n",
    "            # set the pixels in the invalid areas to background\n",
    "            for cords in region.coords:\n",
    "                label_img_filter[cords[0], cords[1]] = 0\n",
    "\n",
    "    # Create binary image from the filtered label image\n",
    "    i_liver = label_img_filter > 0\n",
    "    # show_comparison(img, i_area, 'Found spleen based on area')\n",
    "    io.imshow(i_liver)\n",
    "    io.show()\n",
    "\n",
    "    gt_bin = liver_roi > 0\n",
    "    dice_score = 1 - distance.dice(i_liver.ravel(), gt_bin.ravel())\n",
    "    print(f\"Answer: DICE score {dice_score:.3f}\")\n",
    "\n",
    "\n",
    "    #\n",
    "    # min_hu = 147\n",
    "    # max_hu = 155\n",
    "    # hu_range = np.arange(min_hu, max_hu, 1.0)\n",
    "    # pdf_aorta = norm.pdf(hu_range, mu_aorta, std_aorta)\n",
    "    # pdf_liver = norm.pdf(hu_range, mu_liver, std_liver)\n",
    "    # plt.plot(hu_range, pdf_aorta, 'r--', label=\"aorta\")\n",
    "    # plt.plot(hu_range, pdf_liver, 'g', label=\"liver\")\n",
    "    # plt.title(\"Fitted Gaussians\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    # # Answer = 151\n",
    "\n",
    "\n",
    "### OTSU THRESHOLDING ###\n",
    "def otsu_rotate_image(img_path):\n",
    "    im_name = img_path\n",
    "    im_org = io.imread(im_name)\n",
    "\n",
    "    # angle in degrees - counter clockwise\n",
    "    rotation_angle = 11                                     # Fixed rotation angle           \n",
    "    rot_center = [40, 40]                                   # Fixed rotation center    \n",
    "    rotated_img = rotate(im_org, rotation_angle, center=rot_center)\n",
    "    # rot_byte = img_as_ubyte(rotated_img\n",
    "    # print(f\"Value at (200, 200) : {rot_byte[200, 200]}\")\n",
    "    # io.imshow(rot_byte)\n",
    "    # io.show()\n",
    "\n",
    "    img_gray = color.rgb2gray(rotated_img)\n",
    "\n",
    "    auto_tresh = threshold_otsu(img_gray)\n",
    "    print(f\"Answer: Otsus treshold: {auto_tresh:.2f}\")\n",
    "\n",
    "    # auto_tresh = threshold_otsu(img_out)\n",
    "    # print(f\"Otsus treshold {auto_tresh:.2f}\")\n",
    "\n",
    "    img_thres = img_gray > auto_tresh\n",
    "    io.imshow(img_thres)\n",
    "    io.show()\n",
    "    for_percent = img_thres.sum() / img_thres.size * 100\n",
    "\n",
    "    print(f\"Answer: foreground pixels percent: {for_percent:.0f}\")\n",
    "\n",
    "\n",
    "### LANDMARK BASED REGISTRATION ###\n",
    "def landmark_based_registration(src_path, dst_path):\n",
    "    src_img = io.imread(src_path)\n",
    "    dst_img = io.imread(dst_path)\n",
    "\n",
    "    # src = np.array([[55, 220], [675, 105], [675, 315]])\n",
    "    # dst = np.array([[165, 100], [605, 200], [525, 379]])\n",
    "\n",
    "    # src = np.array([[320, 40], [120, 425], [330, 740]])\n",
    "    # dst = np.array([[320, 80], [155, 380], [300, 670]])\n",
    "\n",
    "    src = np.array([[40, 320], [425, 120], [740, 330]])             # Fixed landmarks\n",
    "    dst = np.array([[80, 320], [380, 155], [670, 300]])\n",
    "\n",
    "    e_x = src[:, 0] - dst[:, 0]\n",
    "    error_x = np.dot(e_x, e_x)\n",
    "    e_y = src[:, 1] - dst[:, 1]\n",
    "    error_y = np.dot(e_y, e_y)\n",
    "    f = error_x + error_y\n",
    "    print(f\"Landmark alignment error F: {f}\")\n",
    "\n",
    "    plt.imshow(src_img)\n",
    "    plt.plot(src[:, 0], src[:, 1], '.r', markersize=12)\n",
    "    plt.title(\"Source image\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(src[:, 0], src[:, 1], '*r', markersize=12, label=\"Source\")\n",
    "    ax.plot(dst[:, 0], dst[:, 1], '*g', markersize=12, label=\"Destination\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Landmarks before alignment\")\n",
    "    plt.show()\n",
    "\n",
    "    # plt.scatter(src[:, 0], src[:, 1])\n",
    "    # plt.scatter(trg[:, 0], trg[:, 1])\n",
    "    # plt.show()\n",
    "    # tform = EuclideanTransform()\n",
    "    tform = SimilarityTransform()                                # Fixed transform              \n",
    "    tform.estimate(src, dst)\n",
    "    print(f\"Answer: scale {tform.scale:.2f}\")\n",
    "\n",
    "    src_transform = matrix_transform(src, tform.params)\n",
    "    # print(src_transform)\n",
    "\n",
    "    e_x = src_transform[:, 0] - dst[:, 0]\n",
    "    error_x = np.dot(e_x, e_x)\n",
    "    e_y = src_transform[:, 1] - dst[:, 1]\n",
    "    error_y = np.dot(e_y, e_y)\n",
    "    f_after = error_x + error_y\n",
    "    print(f\"Aligned landmark alignment error F: {f_after}\")\n",
    "    print(f\"Answer: alignment error change: {f - f_after:.0f}\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(src[:, 0], src[:, 1], '*r', markersize=12, label=\"Source\")\n",
    "    ax.plot(src_transform[:, 0], src_transform[:, 1], '*b', markersize=12, label=\"Source transformed\")\n",
    "    ax.plot(dst[:, 0], dst[:, 1], '*g', markersize=12, label=\"Destination\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Landmarks after alignment\")\n",
    "    plt.show()\n",
    "\n",
    "    warped = warp(src_img, tform.inverse)\n",
    "\n",
    "    val_1 = img_as_ubyte(warped)[200, 200]                      # Fixed pixel coordinates\n",
    "    val_2 = img_as_ubyte(dst_img)[200, 200]\n",
    "    print(f\"Value at (200, 200) : {val_1}\")\n",
    "    print(f\"Value at (200, 200) : {val_2}\")\n",
    "\n",
    "    val_1_b = val_1[2]\n",
    "    val_2_b = val_2[2]\n",
    "    print(f\"Answer: b difference {np.abs(val_2_b - val_1_b)}\")\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(16, 6))\n",
    "    ax[0].imshow(src_img)\n",
    "    ax[0].plot(src[:, 0], src[:, 1], '.r', markersize=12)\n",
    "    # ax[1].plot(dst[:, 0], dst[:, 1], '.r', markersize=12)\n",
    "    ax[1].imshow(warped)\n",
    "    ax[1].plot(src_transform[:, 0], src_transform[:, 1], '.r', markersize=12)\n",
    "    ax[2].imshow(dst_img)\n",
    "    ax[2].plot(dst[:, 0], dst[:, 1], '.r', markersize=12)\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA ALL IMAGES ### \n",
    "def do_pca_on_all_images_in_directory(data_path):\n",
    "    # Find all image files in data dir\n",
    "    in_dir = data_path\n",
    "    all_images = glob.glob(in_dir + \"*.png\")            # Fixed image extension\n",
    "    n_samples = len(all_images)\n",
    "\n",
    "    # Exercise 2\n",
    "    # Read first image to get image dimensions\n",
    "    im_org = io.imread(all_images[0])\n",
    "    im_shape = im_org.shape\n",
    "    height = im_shape[0]\n",
    "    width = im_shape[1]\n",
    "    channels = im_shape[2]\n",
    "    n_features = height * width * channels\n",
    "\n",
    "    print(f\"Found {n_samples} image files. Height {height} Width {width} Channels {channels} n_features {n_features}\")\n",
    "\n",
    "    data_matrix = np.zeros((n_samples, n_features))\n",
    "\n",
    "    idx = 0\n",
    "    for image_file in all_images:\n",
    "        img = io.imread(image_file)\n",
    "        flat_img = img.flatten()\n",
    "        data_matrix[idx, :] = flat_img\n",
    "        idx += 1\n",
    "\n",
    "    # Exercise 3 + 4: The Average image\n",
    "    average_pizza = np.mean(data_matrix, 0)\n",
    "    io.imshow(create_u_byte_image_from_vector(average_pizza, height, width, channels))\n",
    "    plt.title('The Average Pizza')\n",
    "    io.show()\n",
    "\n",
    "    # Find the missing pizza twin\n",
    "    # Exercise 7 + 8\n",
    "    # im_miss = io.imread(\"data/pizzaPCA/super_pizza.png\")\n",
    "    # im_miss_flat = im_miss.flatten()\n",
    "\n",
    "    # Find pizza closest to the average pizza\n",
    "    sub_data = data_matrix - average_pizza\n",
    "    sub_distances = np.linalg.norm(sub_data, axis=1)\n",
    "\n",
    "    # Exercise 9 + 10 + 11\n",
    "    best_match = np.argmin(sub_distances)\n",
    "    best_average_pizza = data_matrix[best_match, :]\n",
    "    worst_match = np.argmax(sub_distances)\n",
    "    worst_average_pizza = data_matrix[worst_match, :]\n",
    "\n",
    "    print(f\"Pizza most away from average pizza {worst_match} : {all_images[worst_match]}\")\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(16, 6))\n",
    "    ax[0].imshow(create_u_byte_image_from_vector(average_pizza, height, width, channels))\n",
    "    ax[0].set_title('The Real average pizza')\n",
    "    ax[1].imshow(create_u_byte_image_from_vector(best_average_pizza, height, width, channels))\n",
    "    ax[1].set_title('The Best Matching Twin pizza')\n",
    "    ax[2].imshow(create_u_byte_image_from_vector(worst_average_pizza, height, width, channels))\n",
    "    ax[2].set_title('The Worst Matching Twin pizza')\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 12\n",
    "    print(\"Computing PCA\")\n",
    "    # pizzas_pca = PCA(n_components=10)\n",
    "    pizzas_pca = PCA(n_components=5)\n",
    "    # pizzas_pca = PCA(n_components=0.80)\n",
    "    pizzas_pca.fit(data_matrix)\n",
    "\n",
    "    # Exercise 13\n",
    "    plt.plot(pizzas_pca.explained_variance_ratio_ * 100)\n",
    "    plt.xlabel('Principal component')\n",
    "    plt.ylabel('Percent explained variance')\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 14\n",
    "    print(f\"Total variation explained by first component {pizzas_pca.explained_variance_ratio_[0] * 100}\")\n",
    "    print(f\"Number of component to explain desired variation {pizzas_pca.n_components_}\")\n",
    "\n",
    "    # Exercise 15\n",
    "    components = pizzas_pca.transform(data_matrix)\n",
    "\n",
    "    # Exercise 16\n",
    "    pc_1 = components[:, 0]\n",
    "    pc_2 = components[:, 1]\n",
    "\n",
    "    # Debug\n",
    "    print(f\"PC_1 : {pc_1.min()} - {pc_1.max()}\")\n",
    "    print(f\"PC_2 : {pc_2.min()} - {pc_2.max()}\")\n",
    "    print(f\"Explained variance: {pizzas_pca.explained_variance_[0]} {pizzas_pca.explained_variance_[1]}\")\n",
    "    print(f\"SQRT Explained variance: {np.sqrt(pizzas_pca.explained_variance_[0])} \"\n",
    "          f\"{np.sqrt(pizzas_pca.explained_variance_[1])}\")\n",
    "\n",
    "    plt.plot(pc_1, pc_2, '.')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 17 + 18\n",
    "    extreme_pc_1_pizza_m = np.argmin(pc_1)\n",
    "    extreme_pc_1_pizza_p = np.argmax(pc_1)\n",
    "    extreme_pc_2_pizza_m = np.argmin(pc_2)\n",
    "    extreme_pc_2_pizza_p = np.argmax(pc_2)\n",
    "\n",
    "    print(f'PC 1 extreme minus pizza: {all_images[extreme_pc_1_pizza_m]}')\n",
    "    print(f'PC 1 extreme minus pizza: {all_images[extreme_pc_1_pizza_p]}')\n",
    "    print(f'PC 2 extreme minus pizza: {all_images[extreme_pc_2_pizza_m]}')\n",
    "    print(f'PC 2 extreme minus pizza: {all_images[extreme_pc_2_pizza_p]}')\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=4, figsize=(16, 6))\n",
    "    ax[0].imshow(create_u_byte_image_from_vector(data_matrix[extreme_pc_1_pizza_m, :], height, width, channels))\n",
    "    ax[0].set_title(f'PC 1 extreme minus pizza')\n",
    "    ax[1].imshow(create_u_byte_image_from_vector(data_matrix[extreme_pc_1_pizza_p, :], height, width, channels))\n",
    "    ax[1].set_title(f'PC 1 extreme plus pizza')\n",
    "    ax[2].imshow(create_u_byte_image_from_vector(data_matrix[extreme_pc_2_pizza_m, :], height, width, channels))\n",
    "    ax[2].set_title(f'PC 2 extreme minus pizza')\n",
    "    ax[3].imshow(create_u_byte_image_from_vector(data_matrix[extreme_pc_2_pizza_p, :], height, width, channels))\n",
    "    ax[3].set_title(f'PC 2 extreme plus pizza')\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(pc_1, pc_2, '.', label=\"All pizzas\")\n",
    "    plt.plot(pc_1[extreme_pc_1_pizza_m], pc_2[extreme_pc_1_pizza_m], \"*\", color=\"green\", label=\"Extreme pizza 1 minus\")\n",
    "    plt.plot(pc_1[extreme_pc_1_pizza_p], pc_2[extreme_pc_1_pizza_p], \"*\", color=\"green\", label=\"Extreme pizza 1 plus\")\n",
    "    plt.plot(pc_1[extreme_pc_2_pizza_m], pc_2[extreme_pc_2_pizza_m], \"*\", color=\"green\", label=\"Extreme pizza 2 minus\")\n",
    "    plt.plot(pc_1[extreme_pc_2_pizza_p], pc_2[extreme_pc_2_pizza_p], \"*\", color=\"green\", label=\"Extreme pizza 2 plus\")\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title(\"pizzas in PCA space\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 19 + 20: First synthetic pizza\n",
    "    w = 60000                                                                           # Fixed weight             \n",
    "    synth_pizza = average_pizza + w * pizzas_pca.components_[0, :]\n",
    "    io.imshow(create_u_byte_image_from_vector(synth_pizza, height, width, channels))\n",
    "    plt.title(\"First synthetic pizza\")\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 22: Major modes of variation\n",
    "    n_modes = 5\n",
    "    # Create a n_modes x 3 plot to show major modes of variation\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=n_modes, figsize=(15, 15))\n",
    "    for m in range(n_modes):\n",
    "        # Average pizza in middle of all\n",
    "        ax[m][1].set_title(\"The Mean pizza\")\n",
    "        ax[m][1].imshow(create_u_byte_image_from_vector(average_pizza, height, width, channels))\n",
    "        # Create mode: synth_pizza = average_pizza + alpha * eigenvector[m]\n",
    "        synth_pizza_plus = average_pizza + 3 * np.sqrt(pizzas_pca.explained_variance_[m]) * pizzas_pca.components_[m, :]\n",
    "        synth_pizza_minus = average_pizza - 3 * np.sqrt(pizzas_pca.explained_variance_[m]) * pizzas_pca.components_[m, :]\n",
    "        ax[m][0].set_title(f\"Mode: {m} minus\")\n",
    "        ax[m][2].set_title(f\"Mode: {m} plus\")\n",
    "        ax[m][0].imshow(create_u_byte_image_from_vector(synth_pizza_minus, height, width, channels))\n",
    "        ax[m][2].imshow(create_u_byte_image_from_vector(synth_pizza_plus, height, width, channels))\n",
    "        ax[m][0].axis('off')\n",
    "        ax[m][1].axis('off')\n",
    "        ax[m][2].axis('off')\n",
    "    fig.suptitle(\"Major modes of pizza variations\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Computing synthetic pizzas\")\n",
    "    n_random = 3\n",
    "    n_components_to_use = 10\n",
    "    n_components_to_use = min(n_components_to_use, pizzas_pca.n_components_)\n",
    "    fig, ax = plt.subplots(ncols=n_random, nrows=n_random, figsize=(10, 10))\n",
    "    for i in range(n_random):\n",
    "        for j in range(n_random):\n",
    "            synth_pizza = average_pizza\n",
    "            for idx in range(n_components_to_use):\n",
    "                w = random.uniform(-1, 1) * 3 * np.sqrt(pizzas_pca.explained_variance_[idx])\n",
    "                synth_pizza = synth_pizza + w * pizzas_pca.components_[idx, :]\n",
    "            ax[i][j].imshow(create_u_byte_image_from_vector(synth_pizza, height, width, channels))\n",
    "            ax[i][j].axis('off')\n",
    "    fig.suptitle(\"Some Random Synthetic pizzas\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 24: Find the missing pizza twin\n",
    "    im_miss = io.imread(\"data/pizzaPCA/super_pizza.png\")                                # Fixed missing pizza\n",
    "    im_miss_flat = im_miss.flatten()\n",
    "    im_miss_flat = im_miss_flat.reshape(1, -1)\n",
    "    pca_coords = pizzas_pca.transform(im_miss_flat)\n",
    "    pca_coords = pca_coords.flatten()\n",
    "\n",
    "    # Exercise 25\n",
    "    plt.plot(pc_1, pc_2, '.', label=\"All pizzas\")\n",
    "    plt.plot(pca_coords[0], pca_coords[1], \"*\", color=\"red\", label=\"Missing pizza\")\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title(\"The Missing pizza in PCA space\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 26\n",
    "    synth_pizza = average_pizza\n",
    "    for idx in range(pizzas_pca.n_components_):\n",
    "        synth_pizza = synth_pizza + pca_coords[idx] * pizzas_pca.components_[idx, :]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "    ax[0].imshow(im_miss)\n",
    "    ax[0].set_title('The Real Missing pizza')\n",
    "    ax[1].imshow(create_u_byte_image_from_vector(synth_pizza, height, width, channels))\n",
    "    ax[1].set_title('The Synthetic Missing pizza')\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 27\n",
    "    comp_sub = components - pca_coords\n",
    "    pca_distances = np.linalg.norm(comp_sub, axis=1)\n",
    "\n",
    "    best_match = np.argmin(pca_distances)\n",
    "    print(f\"Answer: Best matching PCA pizza {all_images[best_match]}\")\n",
    "    best_twin_pizza = data_matrix[best_match, :]\n",
    "    worst_match = np.argmax(pca_distances)\n",
    "    worst_twin_pizza = data_matrix[worst_match, :]\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(16, 6))\n",
    "    ax[0].imshow(im_miss)\n",
    "    ax[0].set_title('The Real Missing pizza')\n",
    "    ax[1].imshow(create_u_byte_image_from_vector(best_twin_pizza, height, width, channels))\n",
    "    ax[1].set_title('The Best Matching Twin pizza')\n",
    "    ax[2].imshow(create_u_byte_image_from_vector(worst_twin_pizza, height, width, channels))\n",
    "    ax[2].set_title('The Worst Matching Twin pizza')\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Exercise 28\n",
    "    n_best = 5\n",
    "    best = np.argpartition(pca_distances, n_best)\n",
    "    fig, ax = plt.subplots(ncols=n_best, figsize=(16, 6))\n",
    "    for i in range(n_best):\n",
    "        candidate_twin_pizza = data_matrix[best[i], :]\n",
    "        ax[i].imshow(create_u_byte_image_from_vector(candidate_twin_pizza, height, width, channels))\n",
    "        ax[i].axis('off')\n",
    "\n",
    "    fig.suptitle(f\"The {n_best} most similar pizzas\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course02502",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
